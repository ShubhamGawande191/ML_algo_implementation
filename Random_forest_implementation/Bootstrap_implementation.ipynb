{"cells":[{"cell_type":"markdown","metadata":{"id":"3sNKZq4XrXQh"},"source":["# <font color='red'><b>Bootstrap assignment</b> </font>"]},{"cell_type":"markdown","metadata":{"id":"RAHap1Z3FZC-"},"source":["<b>There will be some functions that start with the word \"grader\" ex: grader_sampples(), grader_30().. etc, you should not change those function definition.\n","\n","Every Grader function has to return True.</b>"]},{"cell_type":"markdown","metadata":{"id":"cuxBq_bvrwh2"},"source":["<font color='blue'> <b>Importing packages</b> </font>"]},{"cell_type":"code","execution_count":1581,"metadata":{"id":"m6ag91ijrQOs","executionInfo":{"status":"ok","timestamp":1659523302075,"user_tz":-330,"elapsed":392,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["import numpy as np # importing numpy for numerical computation\n","from sklearn.datasets import load_boston # here we are using sklearn's boston dataset\n","from sklearn.metrics import mean_squared_error # importing mean_squared_error metric\n","from sklearn.tree import DecisionTreeRegressor\n","import warnings\n","warnings.filterwarnings(\"ignore\")"]},{"cell_type":"code","execution_count":1582,"metadata":{"id":"CcHOsONTt1K_","executionInfo":{"status":"ok","timestamp":1659523302754,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["boston = load_boston()\n","x=boston.data #independent variables\n","y=boston.target #target variable"]},{"cell_type":"code","execution_count":1583,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pc1htEFYuLRj","outputId":"842826a4-3a69-4312-f612-038eaeb974a3","executionInfo":{"status":"ok","timestamp":1659523302755,"user_tz":-330,"elapsed":14,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["(506, 13)"]},"metadata":{},"execution_count":1583}],"source":["x.shape"]},{"cell_type":"code","execution_count":1584,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kQle3T_wuOa3","outputId":"16470cfa-5e00-4f3b-820d-5a9b512300ec","executionInfo":{"status":"ok","timestamp":1659523302755,"user_tz":-330,"elapsed":11,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[6.3200e-03, 1.8000e+01, 2.3100e+00, 0.0000e+00, 5.3800e-01,\n","        6.5750e+00, 6.5200e+01, 4.0900e+00, 1.0000e+00, 2.9600e+02,\n","        1.5300e+01, 3.9690e+02, 4.9800e+00],\n","       [2.7310e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n","        6.4210e+00, 7.8900e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n","        1.7800e+01, 3.9690e+02, 9.1400e+00],\n","       [2.7290e-02, 0.0000e+00, 7.0700e+00, 0.0000e+00, 4.6900e-01,\n","        7.1850e+00, 6.1100e+01, 4.9671e+00, 2.0000e+00, 2.4200e+02,\n","        1.7800e+01, 3.9283e+02, 4.0300e+00],\n","       [3.2370e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n","        6.9980e+00, 4.5800e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n","        1.8700e+01, 3.9463e+02, 2.9400e+00],\n","       [6.9050e-02, 0.0000e+00, 2.1800e+00, 0.0000e+00, 4.5800e-01,\n","        7.1470e+00, 5.4200e+01, 6.0622e+00, 3.0000e+00, 2.2200e+02,\n","        1.8700e+01, 3.9690e+02, 5.3300e+00]])"]},"metadata":{},"execution_count":1584}],"source":["x[:5]"]},{"cell_type":"markdown","metadata":{"id":"AEa_HqRZloH4"},"source":["## <font color='red'><b>Task 1</b></font>"]},{"cell_type":"markdown","metadata":{"id":"YQ5q8IxHNRk3"},"source":["<font color='red'> <b>Step - 1</b></font>"]},{"cell_type":"markdown","metadata":{"id":"GJCFCaOzl7Mr"},"source":["*  <font color='blue'><b>Creating samples</b></font><br>\n","    <b> Randomly create 30 samples from the whole boston data points</b>\n","    *  Creating each sample: Consider any random 303(60% of 506) data points from whole data set and then replicate any 203 points from the sampled points\n","    \n","     For better understanding of this procedure lets check this examples, assume we have 10 data points [1,2,3,4,5,6,7,8,9,10], first we take 6 data points randomly , consider we have selected [4, 5, 7, 8, 9, 3] now we will replicate 4 points from [4, 5, 7, 8, 9, 3], consder they are [5, 8, 3,7] so our final sample will be [4, 5, 7, 8, 9, 3, 5, 8, 3,7]\n","* <font color='blue'><b> Create 30 samples </b></font>\n","    *  Note that as a part of the Bagging when you are taking the random samples <b>make sure each of the sample will have different set of columns</b><br>\n","Ex: Assume we have 10 columns[1 ,2 ,3 ,4 ,5 ,6 ,7 ,8 ,9 ,10] for the first sample we will select [3, 4, 5, 9, 1, 2] and for the second sample  [7, 9, 1, 4, 5, 6, 2] and so on...\n","Make sure each sample will have atleast 3 feautres/columns/attributes\n","\n","* <font color='red'><b> Note - While selecting the random 60% datapoints from the whole data, make sure that the selected datapoints are all exclusive, repetition is not allowed. </b></font>"]},{"cell_type":"markdown","metadata":{"id":"zUqFEBSvNjCa"},"source":["<font color='red'><b>Step - 2 </b></font>"]},{"cell_type":"markdown","metadata":{"id":"uqi9AhCYNq3Z"},"source":["<font color='blue'><b>Building High Variance Models on each of the sample and finding train MSE value</b></font>"]},{"cell_type":"markdown","metadata":{"id":"-lLBnZHXOFln"},"source":["*  Build a regression trees on each of 30 samples.\n","*  Computed the predicted values of each data point(506 data points) in your corpus.\n","*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{30}\\sum_{k=1}^{30}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$\n","*  Now calculate the $MSE =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$"]},{"cell_type":"markdown","metadata":{"id":"Kls23JLnSN23"},"source":["<font color='red'> <b>Step - 3 </b></font>"]},{"cell_type":"markdown","metadata":{"id":"rz2GchkGSWnh"},"source":["*  <font color='blue'><b>Calculating the OOB score </b></font>"]},{"cell_type":"markdown","metadata":{"id":"DGHkVV2kSibm"},"source":["*  Predicted house price of $i^{th}$ data point $y^{i}_{pred} =  \\frac{1}{k}\\sum_{\\text{k= model which was buit on samples not included } x^{i}}(\\text{predicted value of } x^{i} \\text{ with } k^{th} \\text{ model})$.\n","*  Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."]},{"cell_type":"markdown","metadata":{"id":"RK860ocxTyoz"},"source":["# <font color='red'><b>Task 2</b></font>"]},{"cell_type":"markdown","metadata":{"id":"1dme-N6TUCrY"},"source":["*  <font color='blue'><b>Computing CI of OOB Score and Train MSE</b></font>\n","  *   Repeat Task 1 for 35 times, and for each iteration store the Train MSE and OOB score </li>\n","<li> After this we will have 35 Train MSE values and 35 OOB scores </li>\n","<li> using these 35 values (assume like a sample) find the confidence intravels of MSE and OOB Score </li>\n","<li> you need to report CI of MSE and CI of OOB Score </li>\n","<li> Note: Refer the Central_Limit_theorem.ipynb to check how to find the confidence intravel</li>\n","</ol>"]},{"cell_type":"markdown","metadata":{"id":"O6UcH1x9Uwrj"},"source":["# <font color='red'><b>Task 3</b></font>"]},{"cell_type":"markdown","metadata":{"id":"bOC_AgsLU7OH"},"source":["*  <font color='blue'><b>Given a single query point predict the price of house.</b></font>"]},{"cell_type":"markdown","metadata":{"id":"HYs5jSFdVILe"},"source":["Consider xq= [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60] \n","Predict the house price for this point as mentioned in the step 2 of Task 1."]},{"cell_type":"markdown","metadata":{"id":"u6rShd89t552"},"source":["## <font color='red'><b>A few key points</b></font>"]},{"cell_type":"markdown","metadata":{"id":"XdgTUXTouHEd"},"source":["* Remember that the datapoints used for calculating MSE score contain some datapoints that were initially used while training the base learners (the 60% sampling). This makes these datapoints partially seen (i.e. the datapoints used for calculating the MSE score are a mixture of seen and unseen data).\n","Whereas, the datapoints used for calculating OOB score have only the unseen data. This makes these datapoints completely unseen and therefore appropriate for testing the model's performance on unseen data.\n","\n","* Given the information above, if your logic is correct, the calculated MSE score should be less than the OOB score.\n","\n","* The MSE score must lie between 0 and 10.\n","* The OOB score must lie between 10 and 35.\n","\n","* The difference between the left nad right confidence-interval values must not be more than 10. Make sure this is true for both MSE and OOB confidence-interval values."]},{"cell_type":"markdown","metadata":{"id":"V2fHTdS_zpgG"},"source":["# <font color='blue'> <b>Task - 1</b></font>"]},{"cell_type":"markdown","metadata":{"id":"e0yGBuryOwHz"},"source":["<font color='blue'><b>Step - 1</b></font>"]},{"cell_type":"markdown","metadata":{"id":"lJXX8vf3z073"},"source":["*  <font color='blue'> <b>Creating samples</b></font>"]},{"cell_type":"markdown","metadata":{"id":"CSVaWG1F4uCZ"},"source":["<font color='Orange'><b>Algorithm</b></font>\n","\n","![alt text](https://i.imgur.com/OfcFrUP.jpg/)"]},{"cell_type":"markdown","metadata":{"id":"f_oWoN97BhDY"},"source":["*  <font color='blue'><b> Write code for generating samples</b></font>"]},{"cell_type":"code","execution_count":1585,"metadata":{"id":"Ph_6D2SDzz7F","executionInfo":{"status":"ok","timestamp":1659523302755,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["def generating_samples(input_data, target_data):\n","\n","    '''In this function, we will write code for generating 30 samples '''\n","    # you can use random.choice to generate random indices without replacement\n","    # Please have a look at this link https://docs.scipy.org/doc/numpy-1.16.0/reference/generated/numpy.random.choice.html for more details\n","    # Please follow above pseudo code for generating samples \n","    selecting_rows = np.random.choice(len(input_data), size=int(0.6*len(input_data)), replace=False)\n","    replacing_rows = np.random.choice(selecting_rows, size=int(0.4015*len(input_data)), replace=False)\n","    selected_columns = np.array(np.random.choice(a=input_data.shape[1], size=np.random.randint(3,input_data.shape[1]), replace=False))\n","    sample_data = input_data[selecting_rows[:, None], selected_columns]\n","    target_of_sample_data = target_data[selecting_rows]\n","\n","    # Replacating Data\n","    replicated_sample_data = input_data[replacing_rows[:, None], selected_columns]\n","    target_of_replicated_sample_data = target_data[replacing_rows]\n","\n","    # Concatinating data\n","    final_sample_data = np.vstack((sample_data, replicated_sample_data))\n","    final_target_data = np.vstack((target_of_sample_data.reshape(-1,1), target_of_replicated_sample_data.reshape(-1,1)))\n","    return final_sample_data, final_target_data, selecting_rows, selected_columns\n","\n","    # return sampled_input_data , sampled_target_data,selected_rows,selected_columns\n","    # note please return as lists"]},{"cell_type":"markdown","metadata":{"id":"MivEQFlm7iOg"},"source":["<font color='cyan'> <b> Grader function - 1 </b> </fongt>"]},{"cell_type":"code","execution_count":1586,"metadata":{"id":"AVvuhNzm7uld","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659523302756,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"0732d2bb-f40e-473b-8e33-366bb7f63e85"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1586}],"source":["def grader_samples(a,b,c,d):\n","    length = (len(a)==506  and len(b)==506)\n","    sampled = (len(a)-len(set([str(i) for i in a]))==203)\n","    rows_length = (len(c)==303)\n","    column_length= (len(d)>=3)\n","    assert(length and sampled and rows_length and column_length)\n","    return True\n","a,b,c,d = generating_samples(x, y)\n","grader_samples(a,b,c,d)"]},{"cell_type":"markdown","metadata":{"id":"b4LSsmn4Jn2_"},"source":["*  <font color='blue'> <b>Create 30 samples </b>"]},{"cell_type":"markdown","metadata":{"id":"3ec7MN6sL2BZ"},"source":["![alt text](https://i.imgur.com/p8eZaWL.jpg)"]},{"cell_type":"code","execution_count":1587,"metadata":{"id":"XXlKWjCcBvTk","executionInfo":{"status":"ok","timestamp":1659523302756,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["# Use generating_samples function to create 30 samples \n","# store these created samples in a list\n","list_input_data = []\n","list_output_data = []\n","list_selected_rows = []\n","list_selected_columns = []\n","\n","for i in range(30):\n","    a, b, c, d = generating_samples(x, y)\n","    list_input_data.append(a)\n","    list_output_data.append(b)\n","    list_selected_rows.append(c)\n","    list_selected_columns.append(d)"]},{"cell_type":"markdown","metadata":{"id":"MXUz9VFiMQkh"},"source":["<font color='cyan'> <b>Grader function - 2 </b></font>"]},{"cell_type":"code","execution_count":1588,"metadata":{"id":"hCvIq8NuMWOC","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1659523302756,"user_tz":-330,"elapsed":7,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"3c89e3d2-ecdf-419f-e194-b0230aaf3cab"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":1588}],"source":["def grader_30(a):\n","    assert(len(a)==30 and len(a[0])==506)\n","    return True\n","grader_30(list_input_data)"]},{"cell_type":"markdown","metadata":{"id":"7Pv-mkZkO6dh"},"source":["<br>"]},{"cell_type":"markdown","metadata":{"id":"whaHCPB0O8qF"},"source":["<font color='red'><b>Step - 2 </b></font>"]},{"cell_type":"markdown","metadata":{"id":"XBy4zXSWPtU8"},"source":["<font color='orange'><b>Flowchart for building tree</b></font>"]},{"cell_type":"markdown","metadata":{"id":"5xvH06HPQBdP"},"source":["![alt text](https://i.imgur.com/pcXfSmp.png)"]},{"cell_type":"markdown","metadata":{"id":"WRwPO_uHQjul"},"source":["*  <font color='blue'><b> Write code for building regression trees</b></font>"]},{"cell_type":"code","execution_count":1589,"metadata":{"id":"YWQp6tRwMthq","executionInfo":{"status":"ok","timestamp":1659523302757,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["def build_reg_tree(list_ip_data, list_op_data):\n","    \"\"\"\n","    Function to build regressgion tree\n","    INPUT:\n","    list_ip_data = list of sample data created after generating samples\n","    list_op_data = list of target data created after generating samples\n","\n","    OUTPUT:\n","    returns mutiple models after fiting data\n","    \"\"\"\n","    models = []\n","    for i in range(30):\n","        dt = DecisionTreeRegressor()\n","        dt.fit(list_ip_data[i], list_op_data[i])\n","        models.append(dt)\n","    return models"]},{"cell_type":"code","source":["all_models = build_reg_tree(list_input_data, list_output_data)"],"metadata":{"id":"2XtPg2dvE5yC","executionInfo":{"status":"ok","timestamp":1659523303241,"user_tz":-330,"elapsed":490,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"execution_count":1590,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"21j8BKfAQ1U8"},"source":["<font color='orange'><b>Flowchart for calculating MSE </b></font>"]},{"cell_type":"markdown","metadata":{"id":"8Q0mTBD2RBx_"},"source":["![alt text](https://i.imgur.com/sPEE618.png)"]},{"cell_type":"markdown","metadata":{"id":"6e-UamlHRjPy"},"source":["After getting predicted_y for each data point, we can use sklearns mean_squared_error to calculate the MSE between predicted_y and actual_y."]},{"cell_type":"markdown","metadata":{"id":"TnIMT7_oR312"},"source":["*  <font color='blue'><b> Write code for calculating MSE</b></font>"]},{"cell_type":"code","execution_count":1591,"metadata":{"id":"qWhcvMRWRA9b","executionInfo":{"status":"ok","timestamp":1659523303242,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["def calculate_mse(input_data, output_data, cols_selected, reg_trees):\n","    \"\"\"\n","    Function to calculate MSE\n","    INPUT:\n","    input_data = independent variables of given data\n","    output_data = target variable of given data\n","    cols_selected = list of randomly selected column indices after random sampling\n","    reg_trees = multiple models of DecisionTree\n","\n","    OUTPUT:\n","    returns mse value between actual_y and median of predicted_y's\n","    \"\"\"\n","    array_of_Y = [] # list to store y_predicted\n","\n","    for i in range(len(cols_selected)):\n","        # all data points for selected column indices\n","        datapoints = input_data[:, cols_selected[i]]\n","        # predict y \n","        predicted_y = reg_trees[i].predict(datapoints)\n","        array_of_Y.append(predicted_y)\n","\n","    array_of_Y = np.array(array_of_Y).T # Reshaping the array\n","    median = np.median(array_of_Y, axis=1) # median along axis=1\n","\n","    return mean_squared_error(y, median) # MSE"]},{"cell_type":"code","source":["mse = calculate_mse(x, y, list_selected_columns, all_models)\n","print(\"Mean Squared Error : \", mse)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"p0qhZEQNA2R9","executionInfo":{"status":"ok","timestamp":1659523303243,"user_tz":-330,"elapsed":8,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"5c17bb3d-73ae-41d5-d50a-ee181f837dde"},"execution_count":1592,"outputs":[{"output_type":"stream","name":"stdout","text":["Mean Squared Error :  0.05849925889328065\n"]}]},{"cell_type":"markdown","metadata":{"id":"RuclPDMnSz8F"},"source":["<font color='blue'><b>Step - 3 </b></font>"]},{"cell_type":"markdown","metadata":{"id":"ESb9FSIDTM5V"},"source":["<font color='orange'><b>Flowchart for calculating OOB score</b></font>"]},{"cell_type":"markdown","metadata":{"id":"HB-d6NMETbd9"},"source":["![alt text](https://i.imgur.com/95S5Mtm.png)"]},{"cell_type":"markdown","metadata":{"id":"WW3GOcFzTqbt"},"source":["Now calculate the $OOB Score =  \\frac{1}{506}\\sum_{i=1}^{506}(y^{i} - y^{i}_{pred})^{2}$."]},{"cell_type":"markdown","metadata":{"id":"zBqcS03pUYSZ"},"source":["*  <font color='blue'><b> Write code for calculating OOB score </b></font>"]},{"cell_type":"code","source":["def calculate_oob_score(input_data, output_data, rows_selected, cols_selected, reg_trees):\n","    \"\"\"\n","    Function to calculate OOBScore\n","    INPUT:\n","    input_data = independent variables of given data\n","    output_data = target variable of given data\n","    rows_selected = list of randomly selected row indices after random sampling\n","    cols_selected = list of randomly selected column indices after random sampling\n","    reg_trees = multiple models of DecisionTree\n","\n","    OUPUT:\n","    returns oob_score\n","    \"\"\"\n","    final_median = [] # to store all median values\n","\n","    for i in range(len(input_data)):\n","        y_scores = [] # to store all y_predicted values\n","        for idx in range(len(rows_selected)):\n","            # if a point(index) is not available in selected_rows\n","            if i not in rows_selected[idx]: \n","                model = reg_trees[idx] # DT model\n","                # all row data points belonging to selected columns\n","                x_datapoints = input_data[i][cols_selected[idx]]\n","                x_datapoints = np.array(x_datapoints).reshape(1, -1)\n","                y_predict = model.predict(x_datapoints) # predict y\n","                y_scores.append(y_predict)\n","        y_scores_arr = np.array(y_scores)\n","        y_median = np.median(y_scores_arr) # median of y predicted\n","        final_median.append(y_median)\n","\n","    # OOBScore\n","    temp_oob = 0\n","    for j in range(len(x)):\n","        temp_oob += ((output_data[j] - final_median[j]) ** 2)\n","    final_oob = temp_oob/len(output_data) # OOB score\n","    return final_oob"],"metadata":{"id":"7K0SfYiM79wF","executionInfo":{"status":"ok","timestamp":1659523303243,"user_tz":-330,"elapsed":6,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"execution_count":1593,"outputs":[]},{"cell_type":"code","source":["oob_score = calculate_oob_score(x, y, list_selected_rows, list_selected_columns, all_models)\n","print(\"OOBScore : \", oob_score)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JqpBtc8qNMZP","executionInfo":{"status":"ok","timestamp":1659523303749,"user_tz":-330,"elapsed":511,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"6477b4bc-2b0b-4a37-93b4-b25144519ae8"},"execution_count":1594,"outputs":[{"output_type":"stream","name":"stdout","text":["OOBScore :  15.092809427460043\n"]}]},{"cell_type":"markdown","metadata":{"id":"sbuiwX3OUjUI"},"source":["# <font color='blue'><b>Task 2</b></font>"]},{"cell_type":"code","execution_count":1595,"metadata":{"id":"ceW5-D88Uswi","executionInfo":{"status":"ok","timestamp":1659523303749,"user_tz":-330,"elapsed":3,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["def bagging(ip_data, op_data, n, m_samples):\n","    \"\"\"\n","    Function to calculate MSE and OOB score multiple times\n","    INPUT:\n","    ip_data = independent variables of given data\n","    op_data = target variable of given data\n","    n = number of times bagging\n","    m_samples = number of times samples need to be generated\n","\n","    OUTPUT:\n","    returns list of MSE values and list of OOB scores\n","    \"\"\"\n","    mse_list = []\n","    oob_list = []\n","    # No. of times bagging \n","    for times in range(n):\n","        list_selected_rows = []\n","        list_selected_columns = []\n","        list_input_data = []\n","        list_output_data = []\n","        # No. of times samples need to be generated\n","        for sample in range(m_samples):\n","            a,b,c,d = generating_samples(ip_data, op_data)\n","            list_input_data.append(a)\n","            list_output_data.append(b)\n","            list_selected_rows.append(c)\n","            list_selected_columns.append(d)\n","\n","        # Build regression tree of 30 DT models\n","        all_models = build_reg_tree(list_input_data, list_output_data)\n","        # MSE value\n","        mse = calculate_mse(ip_data, op_data, list_selected_columns, all_models)\n","        # OOB score\n","        oob_score = calculate_oob_score(ip_data, op_data, list_selected_rows, list_selected_columns, all_models)\n","        mse_list.append(mse)\n","        oob_list.append(oob_score)\n","        \n","    return np.array(mse_list), np.array(oob_list)"]},{"cell_type":"code","source":["n = 35 # number of times task 1 is repeated\n","m_samples = 30 # number of times samples need to be generated\n","all_mse, all_oob = bagging(x, y, n, m_samples)"],"metadata":{"id":"54Toi-1sTdP-","executionInfo":{"status":"ok","timestamp":1659523324580,"user_tz":-330,"elapsed":20833,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"execution_count":1596,"outputs":[]},{"cell_type":"code","source":["def confidence_interval(list_of_val):\n","    \"\"\"\n","    Function to calculate confidence interval\n","    INPUT:\n","    list_of_val = list of values generated after using some function\n","\n","    OUTPUT:\n","    returns 95% confidence interval of input values\n","    \"\"\"\n","    # mean of input values\n","    mean = np.round(np.mean(list_of_val), 3)\n","    # standard deviation of input values\n","    std_dev = np.round(np.std(list_of_val), 3)\n","    # lower limit confidence interval\n","    lower_limit = mean - 2 * (std_dev/np.sqrt(len(list_of_val))) \n","    # upper limit of confidence interval\n","    upper_limit = mean + 2 * (std_dev/np.sqrt(len(list_of_val)))\n","    return [lower_limit, upper_limit]"],"metadata":{"id":"Q9JQl7nMT3MU","executionInfo":{"status":"ok","timestamp":1659523324582,"user_tz":-330,"elapsed":19,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"execution_count":1597,"outputs":[]},{"cell_type":"code","source":["# confidence interval of MSE\n","ci_mse = confidence_interval(all_mse)\n","# confidence interval of OOB score\n","ci_oob = confidence_interval(all_oob)"],"metadata":{"id":"91drz8mmY0C3","executionInfo":{"status":"ok","timestamp":1659523324582,"user_tz":-330,"elapsed":18,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"execution_count":1598,"outputs":[]},{"cell_type":"code","source":["print(\"Confidence Interval of MSE :\", ci_mse)\n","print(\"Confidence Interval of OOBScore :\",ci_oob)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"L6TFnMBQa43t","executionInfo":{"status":"ok","timestamp":1659523324583,"user_tz":-330,"elapsed":18,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"3d4559d7-3c7a-46a1-d973-224cda968cef"},"execution_count":1599,"outputs":[{"output_type":"stream","name":"stdout","text":["Confidence Interval of MSE : [0.07971391705222572, 0.16828608294777428]\n","Confidence Interval of OOBScore : [13.819552819521036, 14.884447180478965]\n"]}]},{"cell_type":"markdown","metadata":{"id":"jKTnJdiBVS_e"},"source":["# <font color='blue'><b>Task 3</b></font>"]},{"cell_type":"markdown","metadata":{"id":"eXxrvZqHV1Fr"},"source":["<font color='orange'><b>Flowchart for Task 3</b></font>"]},{"cell_type":"markdown","metadata":{"id":"NyjwEJ62V6a6"},"source":["<b>Hint: </b> We created 30 models by using 30 samples in TASK-1. Here, we need send query point \"xq\"  to 30 models and perform the regression on the output generated by 30 models."]},{"cell_type":"markdown","metadata":{"id":"0emSwLL7VurD"},"source":["![alt text](https://i.imgur.com/Y5cNhQk.png)"]},{"cell_type":"markdown","metadata":{"id":"29hjwKlWWDfo"},"source":["*  <font color='blue'><b> Write code for TASK 3 </b></font>"]},{"cell_type":"code","execution_count":1600,"metadata":{"id":"i_pUlSD-VYD1","executionInfo":{"status":"ok","timestamp":1659523324583,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}}},"outputs":[],"source":["xq = [0.18,20.0,5.00,0.0,0.421,5.60,72.2,7.95,7.0,30.0,19.1,372.13,18.60]\n","\n","predicted_Y = [] # list to store y_predicted\n","\n","for i in range(len(list_selected_columns)):\n","    # all data points for selected column indices\n","    datapoints = [xq[col] for col in list_selected_columns[i]]\n","    # predict y \n","    predicted_y = all_models[i].predict(np.array((datapoints)).reshape(1,-1))\n","    predicted_Y.append(predicted_y)\n","\n","predicted_Y = np.array(predicted_Y)\n","median = np.median(predicted_Y) # median of predicted values"]},{"cell_type":"code","source":["print(\"Predicted House Price :\", median)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"dQIYFDlmtuso","executionInfo":{"status":"ok","timestamp":1659523324583,"user_tz":-330,"elapsed":9,"user":{"displayName":"Shubham Gawande","userId":"12844681972008429128"}},"outputId":"14f1d4a0-428c-4d17-be00-07905f8ae1cf"},"execution_count":1601,"outputs":[{"output_type":"stream","name":"stdout","text":["Predicted House Price : 18.5\n"]}]},{"cell_type":"markdown","metadata":{"id":"IOdUi-0xWOJ9"},"source":["<font color='red'><b>Write observations for task 1, task 2, task 3 indetail</b></font>"]},{"cell_type":"markdown","source":["**Task 1** :\n","- We generated 30 samples from input data using row sampling and column sampling.\n","- MSE values are in the range of 0-0.5 every runtime.\n","- OOB Scores are in the range of 10-20 every runtime.\n","- MSE value varied a lot between `[0.002 to 0.211]` every runtime(22 tests):\n","    - 3/22 cases value was lower than `0.01`.\n","    - 8/22 cases value was higher than `0.1`.\n","    - 11/22 cases value was between `[0.02 to 0.099]`\n","- OOB Score varied between `[10 to 20]` every runtime(22 test):\n","     - On average the value was around `15`.\n","     - 5/22 cases value was lower than `13`.\n","     - 2/22 cases value was higher than `17`.\n","     - 15/22 cases value was between `[13 to 17]`\n","- From these observations:\n","    - MSE values are a little unreliable as they tend to vary a lot for the same type of dataset.\n","    - OOB scores are fairly reliable as they don't tend to vary as much.\n","\n","**Task 2** :\n","- Here our MSE and OOB score range were pretty consistent. The difference between lower and upper limit for MSE was on average **`0.0575`** and for OOB score the difference was on average **`1.15`** in 95% of the cases.\n","- Only in 1/22 cases MSE value and OOB score was much higher than average **`0.0575`** and **`1.15`** respectively.\n","- 95% of the MSE and OOB score intervals calculated would contain the population mean.\n","\n","**Task 3** :\n","- In task 3 we performed regression on the output generated by 30 DecisionTree models from task 1 which gave us the predicted value as `18.5` most of the time.\n","- Predicted value varied between `18.5` to `19.5`.\n","- Predicted value was higher than `18.5` when:\n","    - OOB score was higher than `17`.\n","    - In some cases OOB score was lesser than `13`.\n","    - In some cases where MSE was very low(`lesser than 0.02`) and OOB score was either lower(`lesser than 14`) or higher(`greater than 17`) than average OOB score(`around 15`)\n","- In cases where MSE was higher(`greater than 0.1`) and OOB score was lower(`lesser than 13`) the predicted value was either `18.5` or very close to it.\n","- After calculating MSE and OOB score only once to generalize the result may mislead our interpretation of the model performance. So finding confidence interval for MSE and OOB score seems to be a good choice as it will give us an average value for both which we can then use to interpret the model, whether it is performing well or not.\n"],"metadata":{"id":"IkbxRIigJyQf"}}],"metadata":{"colab":{"collapsed_sections":[],"name":"Assignment_10_Bootstrap.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.3"}},"nbformat":4,"nbformat_minor":0}