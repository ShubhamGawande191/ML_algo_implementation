{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7eiDWcM_MC3H"
      },
      "source": [
        "# Implement SGD Classifier with Logloss and L2 regularization Using SGD without using sklearn"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfe2NTQtLq11"
      },
      "source": [
        "**There will be some functions that start with the word \"grader\" ex: grader_weights(), grader_sigmoid(), grader_logloss() etc, you should not change those function definition.<br><br>Every Grader function has to return True.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "42Et8BKIxnsp"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn import linear_model\n",
        "from matplotlib import pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NpSk3WQBx7TQ"
      },
      "source": [
        "Creating custom dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "BsMp0oWzx6dv"
      },
      "outputs": [],
      "source": [
        "X, y = make_classification(n_samples=50000, n_features=15, n_informative=10, n_redundant=5,\n",
        "                           n_classes=2, weights=[0.7], class_sep=0.7, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L8W2fg1cyGdX",
        "outputId": "fec30b0e-042d-4fd4-c8f0-187eb9f6f1b7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((50000, 15), (50000,))"
            ]
          },
          "execution_count": 51,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X.shape, y.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "0Kh4dBfVyJMP"
      },
      "outputs": [],
      "source": [
        "# Split the data into train and test\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=15)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0DR_YMBsyOci",
        "outputId": "1ebf3287-1f39-40a2-94aa-9687f486e62c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((37500, 15), (37500,), (12500, 15), (12500,))"
            ]
          },
          "execution_count": 53,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW4OHswfqjHR"
      },
      "source": [
        "## SGD classifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HpvTwDHyQQy",
        "outputId": "d7744b68-d6ef-4294-e62d-f010f1d18242"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "execution_count": 54,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# alpha : float\n",
        "# Constant that multiplies the regularization term. \n",
        "\n",
        "# eta0 : double\n",
        "# The initial learning rate for the ‘constant’, ‘invscaling’ or ‘adaptive’ schedules.\n",
        "\n",
        "clf = linear_model.SGDClassifier(eta0=0.0001, alpha=0.0001, loss='log', random_state=15, penalty='l2', tol=1e-3, verbose=2, learning_rate='constant')\n",
        "clf\n",
        "# Please check this documentation (https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YYaVyQ2lyXcr",
        "outputId": "f5f5011e-1f71-4b11-c0f1-346493cd50bd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-- Epoch 1\n",
            "Norm: 0.77, NNZs: 15, Bias: -0.316653, T: 37500, Avg. loss: 0.455552\n",
            "Total training time: 0.01 seconds.\n",
            "-- Epoch 2\n",
            "Norm: 0.91, NNZs: 15, Bias: -0.472747, T: 75000, Avg. loss: 0.394686\n",
            "Total training time: 0.02 seconds.\n",
            "-- Epoch 3\n",
            "Norm: 0.98, NNZs: 15, Bias: -0.580082, T: 112500, Avg. loss: 0.385711\n",
            "Total training time: 0.03 seconds.\n",
            "-- Epoch 4\n",
            "Norm: 1.02, NNZs: 15, Bias: -0.658292, T: 150000, Avg. loss: 0.382083\n",
            "Total training time: 0.04 seconds.\n",
            "-- Epoch 5\n",
            "Norm: 1.04, NNZs: 15, Bias: -0.719528, T: 187500, Avg. loss: 0.380486\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 6\n",
            "Norm: 1.05, NNZs: 15, Bias: -0.763409, T: 225000, Avg. loss: 0.379578\n",
            "Total training time: 0.05 seconds.\n",
            "-- Epoch 7\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.795106, T: 262500, Avg. loss: 0.379150\n",
            "Total training time: 0.06 seconds.\n",
            "-- Epoch 8\n",
            "Norm: 1.06, NNZs: 15, Bias: -0.819925, T: 300000, Avg. loss: 0.378856\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 9\n",
            "Norm: 1.07, NNZs: 15, Bias: -0.837805, T: 337500, Avg. loss: 0.378585\n",
            "Total training time: 0.07 seconds.\n",
            "-- Epoch 10\n",
            "Norm: 1.08, NNZs: 15, Bias: -0.853138, T: 375000, Avg. loss: 0.378630\n",
            "Total training time: 0.08 seconds.\n",
            "Convergence after 10 epochs took 0.08 seconds\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "SGDClassifier(eta0=0.0001, learning_rate='constant', loss='log',\n",
              "              random_state=15, verbose=2)"
            ]
          },
          "execution_count": 55,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# fit the model\n",
        "clf.fit(X=X_train, y=y_train)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EAfkVI6GyaRO",
        "outputId": "37d9c8c1-e61f-4a8f-cd36-f750bc9ccb1b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[-0.42336692,  0.18547565, -0.14859036,  0.34144407, -0.2081867 ,\n",
              "          0.56016579, -0.45242483, -0.09408813,  0.2092732 ,  0.18084126,\n",
              "          0.19705191,  0.00421916, -0.0796037 ,  0.33852802,  0.02266721]]),\n",
              " (1, 15),\n",
              " array([-0.8531383]))"
            ]
          },
          "execution_count": 56,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "clf.coef_, clf.coef_.shape, clf.intercept_\n",
        "# clf.coef_ will return the weights\n",
        "# clf.coef_.shape will return the shape of weights\n",
        "# clf.intercept_ will return the intercept term"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_-CcGTKgsMrY"
      },
      "source": [
        "## Implement Logistic Regression with L2 regularization Using SGD: without using sklearn\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "zU2Y3-FQuJ3z"
      },
      "source": [
        "\n",
        "<br>\n",
        "\n",
        "* 1. Initialize the weight_vector and intercept term to zeros \n",
        "\n",
        "* 2. Create a loss function\n",
        "\n",
        " $log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$\n",
        "- for each epoch:\n",
        "    - for each batch of data points in train:\n",
        "        - calculate the gradient of loss function w.r.t each weight in weight vector\n",
        "        $dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)})$ <br>\n",
        "        - Calculate the gradient of the intercept\n",
        "           $ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t}))$\n",
        "        - Update weights and intercept\n",
        "        $w^{(t+1)}← w^{(t)}+α(dw^{(t)}) $<br>\n",
        "        $b^{(t+1)}←b^{(t)}+α(db^{(t)}) $\n",
        "    - calculate the log loss for train and test with the updated weights\n",
        "    - append this loss in the list\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "GecwYV9fsKZ9"
      },
      "outputs": [],
      "source": [
        "def initialize_weights(row_vector):\n",
        "    ''' In this function, we will initialize our weights and bias'''\n",
        "    # initialize the weights as 1d array consisting of all zeros similar to the dimensions of row_vector\n",
        "    # use zeros_like function to initialize zero, check this link https://docs.scipy.org/doc/numpy/reference/generated/numpy.zeros_like.html\n",
        "    # initialize bias to zero\n",
        "    w = np.zeros_like(row_vector)\n",
        "    b = 0\n",
        "    return w,b"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A7I6uWBRsKc4",
        "outputId": "1ecb4fa2-ab5d-4766-ef0d-991918a430bb"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "w = [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
            "b = 0\n"
          ]
        }
      ],
      "source": [
        "# initialize the weights\n",
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "print('w =',(w))\n",
        "print('b =',str(b))"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "4MI5SAjP9ofN"
      },
      "source": [
        "<font color='cyan'>Grader function - 1 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pv1llH429wG5",
        "outputId": "7e49a19d-aaaa-44c2-b5aa-6bc2b27d6d33"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 59,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dim=X_train[0] \n",
        "w,b = initialize_weights(dim)\n",
        "def grader_weights(w,b):\n",
        "  assert((len(w)==len(dim)) and b==0 and np.sum(w)==0.0)\n",
        "  return True\n",
        "grader_weights(w,b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QN83oMWy_5rv"
      },
      "source": [
        "Compute sigmoid"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPv4NJuxABgs"
      },
      "source": [
        "$sigmoid(z)= 1/(1+exp(-z))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "nAfmQF47_Sd6"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "    ''' In this function, we will return sigmoid of z'''\n",
        "    # compute sigmoid(z) and return\n",
        "    res = 1/(1+np.exp(-z))\n",
        "    return res"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "9YrGDwg3Ae4m"
      },
      "source": [
        "<font color='cyan'>Grader function - 2</font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 61,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P_JASp_NAfK_",
        "outputId": "bd4af3c6-3383-4df1-a492-faa4134ccd14"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 61,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_sigmoid(z):\n",
        "  val=sigmoid(z)\n",
        "  assert(val==0.8807970779778823)\n",
        "  return True\n",
        "grader_sigmoid(2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gS7JXbcrBOFF"
      },
      "source": [
        "Compute loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lfEiS22zBVYy"
      },
      "source": [
        "$log loss = -1*\\frac{1}{n}\\Sigma_{for each Yt,Y_{pred}}(Ytlog10(Y_{pred})+(1-Yt)log10(1-Y_{pred}))$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "VaFDgsp3sKi6"
      },
      "outputs": [],
      "source": [
        "def logloss(y_true,y_pred):\n",
        "    # while dealing with numpy arrays we can use vectorized operations for quicker calculations as compared to using loops\n",
        "    # https://www.pythonlikeyoumeanit.com/Module3_IntroducingNumpy/VectorizedOperations.html\n",
        "    # https://www.geeksforgeeks.org/vectorized-operations-in-numpy/\n",
        "    loss = -1*np.sum(np.mean(y_true*np.log10(y_pred) + (1-y_true)*np.log10(1-y_pred)))\n",
        "\n",
        "    return loss"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Zs1BTXVSClBt"
      },
      "source": [
        "<font color='cyan'>Grader function - 3 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzttjvBFCuQ5",
        "outputId": "be819155-d3cb-4824-9438-e41c9f2c552b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 63,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# round off the value to 8 values\n",
        "def grader_logloss(true,pred):\n",
        "  loss=logloss(true,pred)\n",
        "  assert(np.round(loss,6)==0.076449)\n",
        "  return True\n",
        "true=np.array([1,1,0,1,0])\n",
        "pred=np.array([0.9,0.8,0.1,0.8,0.2])\n",
        "grader_logloss(true,pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tQabIadLCBAB"
      },
      "source": [
        "Compute gradient w.r.to  'w' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YTMxiYKaCQgd"
      },
      "source": [
        "$dw^{(t)} = x_n(y_n − σ((w^{(t)})^{T} x_n+b^{t}))- \\frac{λ}{N}w^{(t)}$ <br>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {
        "id": "NMVikyuFsKo5"
      },
      "outputs": [],
      "source": [
        "# make sure that the sigmoid function returns a scalar value, you can use dot function operation\n",
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = x * (y - sigmoid(np.dot(w.T, x) + b)) - (alpha/N)*w\n",
        "    return dw"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 65,
      "metadata": {
        "id": "fkp70f6vnPqb"
      },
      "outputs": [],
      "source": [
        "def sigmoid(z):\n",
        "  # compute sigmoid(z) and return result\n",
        "  res = 1/(1+np.exp(-z))\n",
        "  return res"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 66,
      "metadata": {
        "id": "0CaG8nOWnIJY"
      },
      "outputs": [],
      "source": [
        "def gradient_dw(x,y,w,b,alpha,N):\n",
        "    '''In this function, we will compute the gardient w.r.to w '''\n",
        "    dw = x * (y - sigmoid(np.dot(w.T, x) + b)) - (alpha/N) * w\n",
        "    return dw"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RUFLNqL_GER9"
      },
      "source": [
        "<font color='cyan'>Grader function - 4 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 67,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WI3xD8ctGEnJ",
        "outputId": "53180bd7-741c-4e40-be3d-71ab1ff3287b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 67,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_dw(x,y,w,b,alpha,N):\n",
        "  grad_dw=gradient_dw(x,y,w,b,alpha,N)\n",
        "  assert(np.round(np.sum(grad_dw),5)==4.75684)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0\n",
        "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
        "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
        "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
        "grad_b=0.5\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_dw(grad_x,grad_y,grad_w,grad_b,alpha,N)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LE8g84_GI62n"
      },
      "source": [
        "Compute gradient w.r.to 'b' "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fHvTYZzZJJ_N"
      },
      "source": [
        "$ db^{(t)} = y_n- σ((w^{(t)})^{T} x_n+b^{t})$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {
        "id": "0nUf2ft4EZp8"
      },
      "outputs": [],
      "source": [
        "# db should be a scalar value\n",
        "def gradient_db(x,y,w,b):\n",
        "    '''In this function, we will compute gradient w.r.to b '''\n",
        "    db = y - sigmoid(np.dot(w.T, x) + b)\n",
        "\n",
        "    return db"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pbcBzufVG6qk"
      },
      "source": [
        "<font color='cyan'>Grader function - 5 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 69,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TfFDKmscG5qZ",
        "outputId": "eea95563-ad75-4bce-9ca7-8939ad0e76e8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 69,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def grader_db(x,y,w,b):\n",
        "  grad_db=gradient_db(x,y,w,b)\n",
        "  assert(np.round(grad_db,4)==-0.3714)\n",
        "  return True\n",
        "grad_x=np.array([-2.07864835,  3.31604252, -0.79104357, -3.87045546, -1.14783286,\n",
        "       -2.81434437, -0.86771071, -0.04073287,  0.84827878,  1.99451725,\n",
        "        3.67152472,  0.01451875,  2.01062888,  0.07373904, -5.54586092])\n",
        "grad_y=0.5\n",
        "grad_b=0.1\n",
        "grad_w=np.array([ 0.03364887,  0.03612727,  0.02786927,  0.08547455, -0.12870234,\n",
        "       -0.02555288,  0.11858013,  0.13305576,  0.07310204,  0.15149245,\n",
        "       -0.05708987, -0.064768  ,  0.18012332, -0.16880843, -0.27079877])\n",
        "alpha=0.0001\n",
        "N=len(X_train)\n",
        "grader_db(grad_x,grad_y,grad_w,grad_b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "wyNIW-ULkN3z"
      },
      "outputs": [],
      "source": [
        "# prediction function used to compute predicted_y given the dataset X\n",
        "def pred(w,b, X):\n",
        "    N = len(X)\n",
        "    predict = []\n",
        "    for p in range(N):\n",
        "        z=np.dot(w,X[p])+b\n",
        "        predict.append(sigmoid(z))\n",
        "    return np.array(predict)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TCK0jY_EOvyU"
      },
      "source": [
        "Implementing logistic regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 71,
      "metadata": {
        "id": "dmAdc5ejEZ25"
      },
      "outputs": [],
      "source": [
        "def train(X_train,y_train,X_test,y_test,epochs,alpha,eta0):\n",
        "    ''' In this function, we will implement logistic regression'''\n",
        "    # Here eta0 is learning rate\n",
        "        \n",
        "    train_loss = []\n",
        "    test_loss = []\n",
        "    w,b = initialize_weights(X_train[0]) # Initialize the weights\n",
        "\n",
        "    # for every epoch\n",
        "    for epoch in range(epochs):\n",
        "      # for every data point(X_train,y_train)\n",
        "      for i, j in zip(X_train, y_train):\n",
        "        # computing gradients w.r.t w and b\n",
        "        dw = gradient_dw(i,j,w,b,alpha,N) \n",
        "        db = gradient_db(i,j,w,b)\n",
        "        # updating w and b\n",
        "        w = w + (eta0 * dw) \n",
        "        b = b + (eta0 * db) \n",
        "\n",
        "      # predicting based on X_train data\n",
        "      train_pred = pred(w, b, X_train)\n",
        "      # computing log loss\n",
        "      loss_x = logloss(y_train, train_pred)\n",
        "      train_loss.append(loss_x)\n",
        "\n",
        "      # predicting based on X_test data\n",
        "      test_pred = pred(w, b, X_test)\n",
        "      # computing log loss\n",
        "      loss_y = logloss(y_test, test_pred)\n",
        "      test_loss.append(loss_y)\n",
        "\n",
        "    return w, b, train_loss, test_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "id": "sUquz7LFEZ6E"
      },
      "outputs": [],
      "source": [
        "# training the model\n",
        "alpha=0.001\n",
        "eta0=0.0001\n",
        "N=len(X_train)\n",
        "epochs=10\n",
        "w,b,train_loss,test_loss=train(X_train,y_train,X_test,y_test,epochs,alpha,eta0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 73,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GQKOwUsckN30",
        "outputId": "5d072062-c6a7-485b-c37c-5e66b144a01f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-0.42320231  0.19097502 -0.14588899  0.33813457 -0.21204102  0.56528013\n",
            " -0.44537754 -0.09169275  0.21798652  0.16980144  0.19524866  0.00226123\n",
            " -0.07784739  0.33881853  0.02215503]\n",
            "-0.8505912574144183\n"
          ]
        }
      ],
      "source": [
        "# print thr value of weights w and bias b\n",
        "print(w)\n",
        "print(b)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "geDLskcFkN30",
        "outputId": "45911ab1-9a57-4c12-c73e-92772855f36c"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(array([[ 0.00016461,  0.00549937,  0.00270137, -0.0033095 , -0.00385432,\n",
              "          0.00511434,  0.00704729,  0.00239538,  0.00871332, -0.01103982,\n",
              "         -0.00180325, -0.00195793,  0.00175631,  0.00029051, -0.00051218]]),\n",
              " array([0.00254704]))"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# these are the results we got after we implemented sgd and found the optimal weights and intercept\n",
        "\n",
        "w-clf.coef_, b-clf.intercept_"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "RAw5OzBIkN31"
      },
      "source": [
        "<font color='cyan'>Grader function - 6 </font>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K47_iEbEkN31",
        "outputId": "9a13e39e-d65a-4b2c-c8f3-c643fa60283c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The custom weights are correct\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# this grader function should return True\n",
        "# the difference between custom weights and clf.coef_ should be less than or equal to 0.05\n",
        "def difference_check_grader(w,b,coef,intercept):\n",
        "    val_array=np.abs(np.array(w-coef))\n",
        "    assert(np.all(val_array<=0.05))\n",
        "    print('The custom weights are correct')\n",
        "    return True\n",
        "difference_check_grader(w,b,clf.coef_,clf.intercept_)   "
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "230YbSgNSUrQ"
      },
      "source": [
        "Plotting train and test loss vs epochs to see that the curve is converging"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "id": "rH1a5tbOPZB9"
      },
      "outputs": [],
      "source": [
        "epoch_list = [i for i in range(0, epochs)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        },
        "id": "FUN8puFoEZtU",
        "outputId": "4a7de327-153f-40d9-cd86-91c698ea6113"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "plt.plot(epoch_list, train_loss, label = \"train_loss\")\n",
        "plt.plot(epoch_list, test_loss, label = \"test_loss\")\n",
        "plt.xlabel(\"Epoch number\")\n",
        "plt.ylabel(\"Log loss\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1 (tags/v3.11.1:a7a450f, Dec  6 2022, 19:58:39) [MSC v.1934 64 bit (AMD64)]"
    },
    "vscode": {
      "interpreter": {
        "hash": "a1cc50a2ef966ab843478f64f87b29731900f0f4fb72d0401f4df05243679b04"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
